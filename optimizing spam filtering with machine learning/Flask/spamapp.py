# -*- coding: utf-8 -*-
"""spamapp

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GIWV2NJRy7R4Rw9jKsdMQ8VyUWxromL-
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

df = pd.read_csv("/content/spam.csv",encoding="latin")
df.head()

df.info()

df.isna().sum()

df.rename ({"v1": "label", "v2":"text"}, inplace=True, axis=1)

df.tail()



from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['label'] = le.fit_transform(df ['label'])

from sklearn.model_selection import train_test_split
X = df['text']
y = df['label']
X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.20, random_state = 0)

print("Before Oversampling, counts of label '1': ()".format (sum(y_train == 1)))
print("Before Oversampling, counts of label '0': {} In".format (sum(y_train == 0)))

nltk.download("stopwords")

import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

import re
corpus =[]
length = len(df)

for i in range(0, length):
  text = re.sub("[^a-zA-Z0-9]","",df["text"][i])
  text = text. lower ()
  text = text.split()
  pe = PorterStemmer()
  stopword = stopwords.words ("english")
  text = [pe.stem(word) for word in text if not word in set(stopword)]
  text ="".join (text)
  corpus. append (text)

corpus

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=35000)
x = cv.fit_transform(corpus).toarray()

import pickle
pickle.dump(cv, open('cv.pkl', 'wb'))

df.describe()

df.shape

df["label"].value_counts().plot(kind="bar",figsize=(12,6))
plt.xticks(np.arange(2),('Non spam','spam'),rotation=0);

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier()

DecisionTreeClassifier()

from sklearn.ensemble import RandomForestClassifier
model1 =RandomForestClassifier()

RandomForestClassifier()

from sklearn.naive_bayes import MultinomialNB
model = MultinomialNB()

MultinomialNB()

from tensorflow.keras.models import Sequential
from tensorflow. keras.layers import Dense

model=Sequential()

X_train.shape

model.add(Dense(units=100, activation="relu", kernel_initializer="random_uniform"))

model.add(Dense(units=1, activation="sigmoid"))

model.compile(optimizer="adam", loss="binary_crossentropy",metrics=['accuracy'])

y_test

def new_review(new_review):
  new_review = new_review
  new_review = re.sub('[^a-zA-Z]', ' ', new_review)
  new_review = new_review.lower ()
  new_review = new_review.split()
  ps = PorterStemmer()
  all_stopwords = stopwords.words ('english')
  all_stopwords.remove('not')
  new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]
  new_review = ' '.join(new_review)
  new_corpus = [new_review]
  new_X_test = cv.transform(new_corpus).toarray ()
  print(new_X_test)
  return new_X_test
new_review = new_review(str(input("Enter_new_review...")))

from flask import Flask, render_template, request
import pickle
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from tensorflow. keras.models import load_model
import os

cv = pickle. load (open('/content/cv.pkl', 'rb'))
app = Flask(__name__)

@app.route('/')
def home():
  return render_template('home. html')

import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('/content/spam.csv',encoding = "ISO-8859-1")

# Clean data 

df.rename(columns={
    'v1': 'label',
    'v2': 'message',
}, inplace=True)

df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)

# Encode labels

le = LabelEncoder()
le.fit(df['label'])
df['label'] = le.transform(df['label'])

df.to_csv('/content/spam.csv', encoding='ISO-8859-1')

joblib.dump(le, '/content/encoder.joblib')

import numpy as np
import pandas as pd
import joblib
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

df = pd.read_csv('/content/spam.csv', encoding = "ISO-8859-1")

# Splits training/test sets

X = df['message']
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Builds model

clf = Pipeline(steps=[
    ('tfidf', TfidfVectorizer()),
    ('scaler', StandardScaler(with_mean=False)),
    ('lr', LogisticRegression())
])

# Trains model

clf.fit(X_train, y_train)

# Evaluates model

predictions = clf.predict(X_test)
accuracy = metrics.accuracy_score(y_test, predictions)
print(f"Logistic Regression Model Accuracy: {(accuracy * 100).round(2)}%")

# Saves model

joblib.dump(clf, '/content/model.joblib')

from flask import Flask, render_template, request
import joblib

app = Flask(__name__)

model = joblib.load('/content/model.joblib')
encoder = joblib.load('/content/encoder.joblib')

@app.route('/')
def main():
    return render_template("/content/index.html")

@app.route('/predict', methods=["POST"])
def predict():
    if request.method == "POST":
        message = request.form['submission']
        prediction = model.predict([message])
        classification = encoder.inverse_transform(prediction)

        return render_template('/content/index.html', message=message, classification=classification)

if __name__ == "__main__":
    app.run(debug=True)